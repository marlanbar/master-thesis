\section{Modelo usando el dataset VarQ}

Comenzamos nuestro trabajo analizando el dataset construido en la tesis de Santiago Moreno. Este dataset fue construido inicialmente con las variantes originales del sitio de VarQ, que consistieron en aproximadamente 400 mutaciones correspondientes a 13 proteínas con 10 variables. Posteriormente en el mismo trabajo se aumentó la cantidad para llegar a las aproximadamente 18 mil variables del dataset VarQ usando otras fuentes como Clinvar y Humsavar. Llamaremos a este dataset \textit{VarQ Completo}. 

\subsection{Variables del dataset VarQ Completo}

A continuación damos una descripción detallada de las variables originales encontradas en el dataset \todo{CITAR SANTI Y MODIFICAR}. 

\begin{itemize}
    \item Variación de Energía (ENE): En \textit{VarQ}, las mutaciones son modeladas con el software FoldX, construye un modelo a partir de una estructura dada, mutando residuos específicos. El software predice el impacto energético de la mutación en la estabilidad de la proteína o, en caso de tratarse de un complejo, en la estabilidad del mismo.
    \item SASA : Es el valor correspondiente a la superficie accesible por parte del solvente, de la cadena lateral del aminoácido. Este valor permite determinar si la cadena lateral se encuentra en la superficie o en el núcleo de la estructura.
    \item Porcentaje de SASA: El porcentaje que representa el SASA sobre el total. Es decir el porcentaje que representa el SASA en función de la estructura de la proteína.
    \item B-Factor (BF): o factor de temperatura, que corresponde a un aminoácido dentro de la proteína. Una mayor temperatura, indica que el aminoácido pertenece a una zona potencialmente de mayor movilidad.
    \item Switchability (SWI): Evalúa cuán propenso a generar un cambio de hélice alfa a hoja beta es un conjunto de aminoácidos.
    \item Aggregability (AGG): El software Tango evalúa cuán
    propenso es un aminoácido a generar agregación en una proteína desde un punto de vista estructural. La agregación es el proceso por el cual proteínas mal formadas
    adoptan una conformación que causa su polimerización en fibrillas agregadas y organizadas. Muchas enfermedades neurodegenerativas (Amiloidosis) están asociadas con la agregación proteica.
    \item Conservación (CONS): Se calcula en bits, siempre y cuando la mutación pueda ser mapeada a una posición en una familia PFam asignada. Cuando una posición tiene un alto valor en bits y la
    misma posición coincide con el aminoácido conservado en la secuencia de la proteína
    interpretamos que dicha posición está altamente conservada. La misma puede estar
    altamente conservada porque es importante estructuralmente o porque es importante para
    la actividad enzimática. Los residuos con alta conservación tendrán un impacto mayor sobre la función pues afectan aminoácidos de la familia.
    \item Sitio Activo (AS): Las posiciones de sitio activo son
    aquellas que se encuentran marcados como unidos a ligandos en los archivos PDB o que
    pertenecen al mismo pocket que se encuentren conteniendo estos residuos nombrados o
    aquellos que pertenezcan al Catalytic Site Atlas.
    \item Interfaz 3DID: Determina si la posición sirve para una interfaz proteína-proteína según la base de datos de 3DID.
    \item Interfaz PDB: Determina si la posición sirve para una interfaz proteína-proteína según la base de datos de PDB.
\end{itemize}


\subsection{Limpieza del dataset VarQ Completo}

Para trabajar con este dataset decidimos verificar la etiqueta de cada una de las variantes, de manera de confirmar que su status siguiera vigente. Para esto recurrimos a las fuentes Clinvar y Humsavar. Realizamos un primer filtrado de estas tablas quedándonos con aquellas variables con un status confirmado: en el caso de Humsavar, aquellas que figuran con la expresión \textit{Polymorphism} y \textit{Disease}, mientras que en Clinvar nos quedamos con aquellas que figuraban como \textit{Benign} y \textit{Pathogenic}, eliminando aquellas con caracterización difusa, por ejemplo, ``factor de riesgo''. 

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{documents/latex/figures/3/interseccion_varq.pdf}
    \caption{Valores en la intersección del dataset VarQ con las tablas Clinvar y Humsavar.}
    \label{fig:interseccion_varq}
\end{figure}

Así, cruzamos los datos con las tablas filtradas Humsavar y Clinvar, y encontramos un subconjunto importante de variantes que no aparecían en ninguna de las dos fuentes. Estas variantes estaban rotuladas en su gran mayoría (94\%) como benignas, por lo que creemos que se consideraron como variantes benignas a todas aquellas a las que no se encontró un reporte. Decidimos remover estas variantes del dataset por considerar que si alguna de ellas estuviera rotulada incorrectamente introduciría ruido. Como puede observarse en la figura \ref{fig:interseccion_varq}, de las 17.869 variantes del dataset, logramos encontrar 2.535 en la tabla de Clinvar, de los cuales sólo 2.397 tenían un estado confirmado como patogénicas, y 138 como benignas. Cruzando el dataset con la tabla Humsavar encontramos una intersección de 6.650 variantes de los cuales 4.667 corresponden a patogénicas y 1.983 son benignas. Decidimos mantener la clasificación de Humsavar en la intersección de los tres conjuntos por considerarla de mayor confiabilidad dado que es un reporte único curado por expertos a diferencia de Clinvar que es una recopilación de variantes de diversa significación clínica, y a menudo presenta conflictos de anotación por discrepancias entre evidencias reportadas. Esto nos deja con un dataset Curado de 7.418 variantes de las cuales 5.377 son patogénicas y 2.041 son benignas. Denominaremos a este dataset \textit{VarQ Curado}. 


\subsection{Descripción estadística del dataset VarQ Curado}

A partir de VarQ Curado estudiaremos sus variables usando estadísticas descriptivas con el objetivo de evaluar la calidad del dataset. La idea es poder tener una noción de la dispersión de nuestros datos, sumado a la cobertura que tenemos de ellos sobre las variantes. En la tabla \ref{tab:descripcion_varq} podemos ver distintas métricas sobre las variables continuas del dataset como la cantidad de variables con valor no nulo (count), la media de los valores (mean), el desvío estándar (std), el valor máximo (max) y los cuartiles. 

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
 & SASA & SASA\% & BFACTOR & SWITCH & AGG & CONS & ENE \\ \hline
mean & 32.11 & 0.15 & 56.45 & 0.38 & 5.02 & 0.33 & 2.91 \\ \hline
std & 39.15 & 0.18 & 71.76 & 0.89 & 17.61 & 0.19 & 4.84 \\ \hline
min & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.13 & -12.64 \\ \hline
25\% & 0.67 & 0.0 & 19.77 & 0.0 & 0.0 & 0.25 & 0.26 \\ \hline
50\% & 15.21 & 0.07 & 37.34 & 0.01 & 0.0 & 0.3 & 1.51 \\ \hline
75\% & 52.15 & 0.27 & 61.14 & 0.28 & 0.16 & 0.37 & 3.89 \\ \hline
max & 246.41 & 0.75 & 755.61 & 8.72 & 100.0 & 4.77 & 57.51 \\ \hline
\end{tabular}
\caption{Descripción de variables continuas del dataset \textit{VarQ Curado}.}
\label{tab:descripcion_varq}
\end{table}

Otro de los puntos importantes durante la exploración del dataset es la detección de variables con muy poca cobertura. En la figura \ref{fig:proporcion_nulos_varq} podemos observar como la variable de sitio activo (ACTIVE\_SITE) no posee datos para casi ninguna variantes (aproximadamente el 95\%), mientras que la variable de conservación (CONS) no posee datos para el 63\% de las variantes. En base a estas observaciones decidimos remover la variable de sitio activo del dataset por considerarla muy poco relevante en términos de cobertura.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.55]{documents/latex/figures/3/proporcion_nulos.pdf}
    \caption{Proporción de variantes con valor nulo por variable del dataset VarQ Curado.}
    \label{fig:proporcion_nulos_varq}
\end{figure}

Otro factor importante a considerar es cuantas variables nulas tienen cada una de las variantes del dataset. En la figura \ref{fig:nulos_varq} podemos observar que existe aproximadamente un 5 \% de variantes que poseen 7 variables nulas de las 10 que contienen el dataset, es decir, prácticamente no tienen ningún tipo de información, y sólo el 2\% de las variantes posee el total de las variables cubiertas. Por el otro lado, casi el 90\% de las variantes tiene a lo sumo 3 variables nulas.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.55]{documents/latex/figures/3/nulos_varq.pdf}
    \caption{Histograma de cantidad de variables nulas del dataset VarQ Curado.}
    \label{fig:nulos_varq}
\end{figure}

\subsection{Modelo creado a partir del dataset Varq Curado}

Una vez definido el dataset, podemos emplear técnicas de aprendizaje automático con el objetivo de generar un predictor de variantes patogénicas. Cabe destacar, que en este dataset VarQ Curado hay una sobrerrepresentación de variantes patogénicas, es decir, que presenta un desbalance (mayor número de variantes patogénicas que benignas) que invierte las propociones observadas en el dataset de humsavar. Empezaremos generando un modelo para poder evaluar de forma preliminar la dificultad del problema. 

Para esto evaluamos diferentes algoritmos de aprendizaje automático: SVM, Regresión Logística y Random Forest. La construcción del pipeline para cada uno de estos algoritmos tuvo tres fases: 

\begin{itemize}
    \item \textbf{Creación del set de entrenamiento y de evaluación}: División (\textit{split}) estratificado (es decir, manteniendo las proporciones originales) del dataset, 66\% para entrenamiento y 33\% para evaluación. 
    \item \textbf{Imputación de las variables}: Se reemplazaron los valores nulos de cada variable por su mediana en caso de las continuas y por el valor más frecuente en el caso de las variables categóricas.
    \item \textbf{Estandarización}: Para el caso de los algoritmos paramétricos (Regresión Logística y SVM) se aplicó una estandarización robusta a outliers. Esta estandarización consiste en restar la mediana del valor y escalar los datos de acuerdo a la distancia intercuartil como se observa en la ecuación \ref{eq:robust_scalr}.
    
    \begin{equation}
        RobustScaling(x_i) = \frac{x_i - Q_2(\textbf{x})}{Q_3(\textbf{x}) - Q_1(\textbf{x})} 
        \label{eq:robust_scalr}
    \end{equation}
    
    
    
\end{itemize}

Luego del preprocesamiento, para cada uno de los algormitmos se realizó una búsqueda de hiperparámetros óptimos a partir de estos datos con la función \texttt{GridSearchCV} de la biblioteca \textit{Scikit-learn}. El objetivo de esta función es evaluar todas las combinaciones de hiperparámetros definidos en un diccionario y retornar el estimador que dio mejores resultados (de acuerdo a una métrica escogida, en este caso el área bajo la curva ROC). Esta métrica a su vez es evaluada a través de validación cruzada (\textit{3-fold Cross Validation}). Random Forest fue el mejor por una leve diferencia. 

% \begin{figure}[H]
%     \centering
%     \includegraphics[scale=0.55]{documents/latex/figures/3/resultados_varq.pdf}
%     \caption{Área bajo la curva ROC para cada uno de los algoritmos evaluados: \textit{Random Forest} (RF), \textit{Logistic Regression} (LR) y \textit{Support Vector Classifier} (SVC)}
%     \label{fig:resultados_varq}
% \end{figure}

\begin{figure}
\centering

\begin{minipage}[b]{0.8\textwidth}
    \includegraphics[width=\textwidth]{documents/latex/figures/3/auc_varq.pdf}
    \caption{Curva AUC del algoritmo Random Forest del dataset VarQ.}
    \label{fig:auc_varq}
\end{minipage}

\hfill
\hfill

\begin{minipage}[b]{\textwidth}
    \includegraphics[width=\textwidth]{documents/latex/figures/3/importances_varq.pdf}
    \caption{Los atributos más importantes del dataset VarQ usando un modelo Random Forest.}
    \label{fig:importance_varq}
\end{minipage}

\end{figure}


\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
              & Precisión & Recall & F1-score \\ \hline
Benignas      & 0.57      & 0.26   & 0.36     \\ \hline
Patogénicas   & 0.77      & 0.93   & 0.84     \\ \hline
Promedio      & 0.71      & 0.74   & 0.71     \\ \hline   
\end{tabular}
\caption{Reporte de métricas del modelo usando el dataset VarQ Curado.}

\label{fig:metrics_varq}
\end{table}

En la figura \ref{fig:importance_varq}, la importancia de los features reportado por el algoritmo Random Forest puso en primer lugar con una gran diferencia a la variable que hace referencia al 3DID, que como mencionamos anteriormente determina si la posición sirve para una interfaz proteína-proteína.  

\newpage

\section{Modelo usando Propiedades Estructurales de la Proteína}

En esta sección generamos un nuevo dataset buscando nuevas fuentes de información de carácter estructural de las proteínas. Estas variables provienen de dos fuentes principales:

\begin{itemize}
    \item El módulo ProtParam proveniente de la biblioteca Biopython,
    \item La base de datos SNVBox del laboratorio Karchin.
\end{itemize}

Para el análisis de estas variables usamos la tabla Humsavar completa, compuesto por 68,523 variantes (o ``mutantes'') de las cuales 39,655 son benignas (58\%) y 28,868 (42\%) están asociadas a enfermedades. 

\subsection{Extracción de variables usando Biopython}

La primera fuente que utilizamos, por su relativa practicidad de uso en la extracción de un conjunto de variables físico químicas de la proteína, fue el módulo ProtParam de la biblioteca Biopython. Esta biblioteca es un set de herramientas escritas en Python, desarrollada por colaboradores para el área de la bioinformática, y posee una licencia de uso libre \todo{[ref]}.
El nombre ProtParam proviene de \textit{Protein Parameters} (parámetros de la proteína) y está basado en la herramienta del server proteómico Expasy \todo{[ref]}. Requiere el \textit{accession number} de la proteína (identificador único) o una subsecuencia de la misma, para poder acceder a los parámetros calculados \todo{[ref]}, que son los siguientes:

\begin{itemize}
    \item Peso molecular
    \item pI Teórico
    \item Composición aminoácida
    \item Composición atómica
    \item Coeficiente de extinción
    \item Período de semi-desintegración o hemivida
    \item Índice de instabilidad
    \item Índice alipático
    \item Promedio de hidropaticidad
\end{itemize}

Para poder utilizar el módulo ProtParam recurrimos a Uniprot con el fin de conseguir el proteoma humano en formato FASTA. El formato FASTA fue desarrollado por David Lipman y William Pearson en 1985, y originalmente fue incluido en un programa del mismo nombre utilizado para el alineamiento múltiple de secuencias \todo{[ref]}. Una archivo FASTA puede incluir diferentes secuencias, no necesariamente de aminoácidos, y cada una de estas secuencias posee una línea de descripción al comienzo que empieza con el símbolo $>$ \todo{[ref]}. Por ejemplo:

\begin{verbatim}
	>P01013 GENE X PROTEIN (OVALBUMIN-RELATED)
	QIKDLLVSSSTDLDTTLVLVNAIYFKGMWKTAFNAEDTREMPFHVTKQESKPVQMMCMNNSFNVATLPAE
	KMKILELPFASGDLSMLVLLPDEVSDLERIEKTINFEKLTEWTNPNTMEKRRVKVYLPQMKIEEKYNLTS
	VLMALGMTDLFIPSANLTGISSAESLKISQAVHGAFMELSEDGIEMAGSTGVIEDIKHSPESEQFRADHP
	FLFLIKHNPTNTIVYFGRYWSP
\end{verbatim}


A partir del proteoma obtenido se extrajeron las secuencias correspondientes a las proteínas del dataset Humsavar, y para cada una de ellas se tomó una subsecuencia de la misma alrededor de la posición donde se produjo la variante.

\vspace{2mm}
\todo{
TODO: Esquema de la subsecuencia
}
\vspace{2mm}

Para cada una de los parámetros calculados en ProtParam, generamos dos variables que buscan reflejar la diferencia generada por la variante. \todo{TODO: Hablar de los métodos usados}.

\subsection{Extracción de variables usando SNVBox}

Además de la información obtenida vía ProtParam, recurrimos a una base de datos llamada SNVBox \todo{[ref]}. Esta base de datos fue elaborada y es actualmente mantenida por el Karchin Lab de Universidad Johns Hopkins. Se encuentra en su versión 3.0 y sigue en desarrollo. \todo{Mencionar algunos papers que usaron esta base}. SNVBox posee alrededor de 90 variables consideradas relevantes para detectar el impacto biológico de un SNV \cite{Wong2011}, como datos sobre la estructura de la proteína, a nivel de aminoácido y también a nivel de los sitios de la proteína donde se encuentra la variante. Otra característica destacable de esta fuente es que posee dichas variables para todos los codones del exoma humano, lo que nos permitió una cobertura alta para las variantes del dataset con el que trabajamos. Las variables utilizadas fueron:

\subsubsection{Variables sobre cambios en la sustitución del Aminoácido (Estructura Primaria)}
\begin{itemize}
    \item Score BLOSUM (AABLOSUM)
    \item Carga (AACharge)
    \item Volumen (AAVolume)
    \item Hidrofobia (AAHydrophobicity)
    \item Score Grantham (AAGrantham)
    \item Polaridad (Polarity)
    \item Score Ex (AAEx)
    \item Score PAM250 (AAPAM250)
    \item Score MJ (AAMJ)
    \item Score HGMD2003 (AAHGMD2003)
    \item Score VB (AAVB)
    \item Transición (Transition)
    \item COSMIC
    \item COSMICvsSWISSPROT
    \item HAPMAP
    \item COSMICvsHAPMAP
\end{itemize}

\subsubsection{Variables a nivel de Proteína (sin considerar sustitución)}

\begin{itemize}
    \item BINDING
    \item ACTIVE\_SITE
    \item SITE
    \item LIPID
    \item BINDING
    \item ACT\_SITE
    \item SITE
    \item LIPID
    \item METAL
    \item CARBOHYD
    \item DNA\_BIND
    \item NP\_BIND
    \item CA\_BIND
    \item DISULFID
    \item SE\_CYS
    \item MOD\_RES
    \item PROPEP
    \item SIGNALP
    \item TRANSMEM
    \item COMPBIAS
    \item REP
    \item MOTIF
    \item ZN\_FING
    \item REGIONS
    \item PPI
    \item RNABD
    \item TF
    \item LOC
    \item MMBRBD
\end{itemize}

\vspace{2mm}
\todo{
TODO:
Diagrama de SNVBOX
}
\vspace{2mm}

\subsection{Descripción estadística del Dataset Estructural}

Luego del proceso del extracción de variables generamos un nuevo dataset cruzando estos atributos con las variantes de Humsavar. En el caso de los atributos relativos a los aminoácidos, pudimos cruzarlos usando la columna del dataset referente al identificador de la proteína, la posición de la variante, y el par de aminoácidos que se intercambiaron. Con los atributos relativos al genoma, pudimos cruzar la información usando la columna RSID (Reference SNP cluster ID). Esta columna identifica a un cluster de variaciones de un sólo nucleótido que pertenece a la misma posición en el genoma (o conjunto de posiciones) \cite{Ostell2007}. 
El dataset resultante (denominado \textit{Dataset Estructural}) está compuesto por 68,5 mil observaciones y 28 variables incluyendo la variable de respuesta (o tipo), de los cuales 39,6 mil son benignas (no se encontraron reportes de enfermedades en la literatura), y 28,8 mil variantes están asociadas a alguna enfermedad. 
Una de las formas que nos permite ver que tan bien las variables de este dataset están separando nuestros tipos de SNPs, es usar reducción de dimensionalidad. El primer método que probamos fue el análisis de componentes principales (PCA), con el que generamos dos componentes, que son combinaciones lineales de nuestras variables iniciales de forma de maximizar la varianza, es decir el par de componentes que mejor explican la información completa.

\todo{TODO: Poner gráfico de PCA}

\subsection{Generación del Modelo}

Con este dataset generamos un modelo basado en un predictor Random Forest. 
Se eligió inicialmente este tipo de predictor por ser el que obtuvo los mejores resultados en el dataset \textit{VarQ Curado}  con respecto a otros predictores (SVMs y Regresión Logística). Otras de las ventajas que aporta este modelo es su facilidad para explicar la importancia de las variables y su relativa baja complejidad computacional \todo{[Citar?]}. 

Para esto volvimos a generar un Pipeline muy similar al de la sección anterior:

\begin{itemize}
\item Para la búsqueda de hiperparámetros usamos \textit{Grid-Search} (búsqueda ``en cuadrícula''). \todo{TODO: Evaluar RandomSearch}. 
\item Las variables se imputaron usando la mediana en el caso de las variables continuas, y con el valor más frecuente para las variables categóricas. 
\item Las variables no fueron escaladas al no ser necesario en algoritmos de clasificacion basados en árboles de decisión, dado que se evalúan las variables de forma independiente. 
\end{itemize}


\subsection{Resultados del Modelo Estructural}

Como puede observarse en la figura \ref{fig:auc_structural}, a partir de este modelo se obtuvo un AUC de 0,71, que supera lo obtenido por el modelo usando el dataset VarQ. Las métricas observadas en la tabla \ref{structural_table} permiten dar cuenta de una precisión del 34\% con respecto a las observaciones patogénicas, es decir, el modelo está reportando una 66\% cantidad de variantes como patogénicas que no lo son (también conocido como error de tipo I), y un recall de 63\%, lo que indica que existe un 34\% de variantes patogénicas en nuestro dataset que no están siendo detectadas por nuestro modelo (error de tipo II). \todo{TODO: Diagrama de errores}.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
              & Precisión & Recall & F1-score \\ \hline
Benignas      & 0.68      & 0.81   & 0.74     \\ \hline
Patogénicas   & 0.65      & 0.47   & 0.54     \\ \hline
Promedio      & 0.66      & 0.67   & 0.66     \\ \hline
\end{tabular}
\caption{Métricas del modelo Random Forest aplicado al dataset estructural.}
\label{structural_table}
\end{table}


\subsection{Importancia de los atributos}

El algoritmo Random Forest nos permite identificar los mejores atributos dado su rango en cada uno de los árboles del clasificador. En este caso, podemos ver que los primeros cuatro atributos refieren a matrices de sustitución. Los siguientes features pertenecen a ProtParam, como la aromaticidad, la flexibilidad y la hidrofobicidad. La hidrofobicidad, o la capacidad de repeler el agua de la subsecuencia de los aminoácidos, es uno de las variables consideradas relevantes para definir la patogenicidad de una proteína, de acuerdo a \cite{Wang2016}. También en la figura \ref{fig:importances_structural}, se observan variables con un nivel de importancia muy similar, como es el caso de PAM250, EX y BLOSUM. Estas variables corresponden a matrices de sustitución. y en la figura \ref{fig:corrplot_structural} podemos corroborar que existe una alta correlación entre ellas. \todo{TODO: Evaluar formas de variar el modelo usando variables que no esten correlacionadas. MRMR?} 

\begin{figure}
\centering
\begin{minipage}[b]{0.8\textwidth}
    \centering
    \includegraphics[width=\textwidth]{documents/latex/figures/3/auc_structural.pdf}
    \caption{Curva AUC del algoritmo Random Forest aplicado al dataset estructural. La línea punteada corresponde a un predictor Random.}
    \label{fig:auc_structural}
\end{minipage}

\hfill
\hfill

\begin{minipage}[b]{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{documents/latex/figures/3/importances_structural.pdf}
    \caption{Los 10 atributos más importantes del modelo Random Forest usando el dataset estructural.}
    \label{fig:importances_structural}
\end{minipage}

\end{figure}


% \subsection{Correlación}

% \begin{figure}[H]
%     \centering
%     \includegraphics[scale=0.8]{documents/latex/figures/3/corrplot_1.pdf}
%     \caption{Test de Correlación de Pearson sobre las variables del dataset estructural. Se puede observar que GRANTHAM se encuentra altamente anti-correlacionado con las matrices PAM y BLOSUM, mientras que estas se encuentran correlacionadas al igual que con EX.}
%     \label{fig:corrplot_structural}
% \end{figure}

\newpage

\section{Modelo usando Variables Genómicas}

Otra de las preguntas que nos hicimos fue si las variables genómicas podían hacer un aporte al modelo, siendo en los genes es donde se produce la mutación que finalmente da origen a la variante en la proteína. En la tabla Humsavar existe, para la mayoría de las mutaciones, el identificador RSID o Reference SNP ID. Un identificador RSID agrupa los distintos reportes que hacen referencia a la misma posición dentro del mismo genoma de referencia (hg19/GRCh37). A partir de este identificador fue posible obtener de la base de datos dbSNP (Versión snp150) datos como ser el cromosoma, la posición y el cambio de nucleótido de la variante. 


\subsection{Variables de Conservación}

En la literatura encontramos que dos de las variables genómicas asociadas a la conservación eran las que daban mejores resultados (modelos FATHMM-MKL \cite{Shihab2015} o VEST \cite{Carter2013}). Esta \textit{conservación} es un término biológico que refiere a las secuencias conservadas, es decir secuencias tanto genéticas como proteicas que se mantienen de forma similar o idéntica en muchas especies que poseen un ancestro evolutivo en común (esta \textit{familia} de especies también se denomina árbol filogenético). En particular, la composición de estas variables consiste en alineamientos múltiples de secuencias genéticas (MSA) de 46 especies de vertebrados, incluyendo Homo Sapiens y otras como Felis catus (gato doméstico), Danio renus (pez cebra) y Equus Caballus (el caballo). En base a este alineamiento se usan dos medidas distintas de conservación, \textbf{PhastCons} \cite{siepel2005evolutionarily} y \textbf{PhyloP} \cite{Pollard2010}, que buscan detectar aquellas regiones en el genoma con mayor nivel de conservación entre las distintas especies. Decidimos incluir en nuestro dataset ambas medidas de conservación, usando el Table Browser de la Universidad de California, Santa Cruz \cite{Karolchik2004}.

\subsection{Variables relativas a la Clase Funcional}

También tomamos en consideración la función de la posición dentro del gen. La base de datos dbSNP define cada SNP de acuerdo a su clase funcional. Si la variación se encuentra cerca del intervalo de un transcripto, pero no en la región codificante, la clase funcional va a depender de la posición de la variación relativa a la estructura del transcripto \cite{Ostell2007}. Por otro lado, si la variación se encuentra en una zona codificante, la clase funcional se va a definir en base a si el alelo de la variación va a resultar en una sustitución sinónima (es decir, el nuevo codón va a formar el mismo aminoácido), una sustitución no sinónima (es decir, el nuevo codón va a formar un aminoácido distinto) o una sustitución sin sentido (en donde la mutación genera un codón de terminación prematuro).

\subsection{Extracción de variables usando SNVBox}

Por último, usamos variables genómicas del dataset SNVBox, que calculan la conservación a 46 vías a nivel de exones, y la cantidad de SNPs conocidos en el exón donde se produjo la variante. \todo{TODO: Describir lista de variables del dataset}

\subsection{Descripción estadística del \textit{Dataset Genómico}}

A partir del dataset generado (\textit{Dataset Genómico}) podemos observar también cómo las variables permiten separar el dataset en dos clusters mucho mejor discriminados gracias a una combinación entre las técnicas de reducción de dimensionalidad PCA y t-SNE.

\todo{TODO: Poner gráficos de PCA y t-SNE}


\subsection{Generación del Modelo}

Luego de realizada la exploración del dataset generamos un modelo basado en Random Forest. Volvimos a utilizar este algoritmo debido a los resultados obtenidos en el dataset VarQ y para facilitar la comparación entre datasets. Este modelo se compone de un \textit{pipeline} de dos fases principales: Imputación, y Entrenamiento. En la fase de imputación se reemplazo los valores nulos por el valor más frecuente en el caso de las variables categóricas (por ejemplo las referentes a las clases funcionales) y con la mediana para las variables continuas. Las variables no fueron escaladas dado que en los algoritmos que involucran árboles de decisión, como Random Forest, las variables son evaluadas una a una y por lo tanto la escala de cada una de ellas no afecta la evaluación de las demás.

Como se puede observar en la figura \ref{fig:auc_genomic} obtuvimos un AUC de 0,89. Este resultado es muy superior a los obtenidos en los modelos anteriores, tanto en \textit{VarQ Curado} como el \textit{Estructural}. 
Analizando la importancia de las variables en el modelo, en la figura \ref{fig:importances_genomic} podemos observar que las variables de conservación están en los primeros dos puestos, confirmando lo obtenido por los trabajos de investigación antes mencionados. Por otro lado, esto genera un interrogante adicional: ¿Cuál es la razón por la que la variable \textit{Conservación} del dataset VarQ no genera un rendimiento similar?


\begin{figure}[H]
    \centering
    \includegraphics[scale=0.55]{documents/latex/figures/3/auc_genomic.pdf}
    \caption{Curva AUC del algoritmo Random Forest usando el dataset genómico. La línea punteada corresponde a un predictor Random.}
    \label{fig:auc_genomic}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.55]{documents/latex/figures/3/importances_genomic.pdf}
    \caption{Los 10 atributos más importantes del dataset genómico usando un modelo Random Forest.}
    \label{fig:importances_genomic}
\end{figure}

Como podemos observar en la figura \ref{fig:importances_genomic}, el poder informativo de las variables de conservación es muy similar. La pregunta que nos hacemos en este caso es: ¿Las dos primeras variables de conservación están en los primeros dos lugares porque están altamente correlacionadas o aportan diferente información sobre las variables? En la figura \todo{[x]} podemos observar que estas variables se encuentran correlacionadas.  \todo{TODO: Hacer gráfico de correlación}. 

\todo{TODO: Gráfico de correlación y observaciones}

% \subsection{Descripción}
% \subsection{Correlación}
% \subsection{Resultados}


\newpage

\section{Integrando el dataset estructural y el genómico}

Finalmente, unimos los dos conjuntos de variables para ver si la integración de ambos datasets representan una mejora frente a los resultados del modelo genómico. A este nuevo dataset lo denominamos \textit{Dataset Integral}. Las variantes usadas fueron las encontradas en la tabla Humsavar. 

\subsection{Generación del Modelo}

Para este modelo preliminar volvimos a utilizar Random Forest, repitiendo las dos fases de imputación y entrenamiento. En la fase de imputación usamos la mediana para los valores nulos de las variables continuas y el valor más frecuente en las variables categóricas. Como se puede observar en la figura \ref{fig:auc_integral}, no hubo una mejora significativa con respecto a los otros modelos. Un análisis de \textit{Feature Importance} muestra que las variables de conservación siguen encabezando la lista de las variables más importantes del modelo (ver figura \ref{fig:importances_integral}). Una posible hipótesis que explicaría estos resultados es que las variables del dataset genómico aparecen en la mayoría de los árboles y permiten dividir mucho más eficientemente las variantes que las del dataset estructural, y por lo tanto se pierde el subconjunto de observaciones detectadas por la información de este dataset. Una forma de observar este efecto es cuantificar dichas variantes, es decir, ver si efectivamente el dataset estructural esta detectando una cantidad significativa de variantes no encontradas por el model genómico que no aparecen en este nuevo modelo. 

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.55]{documents/latex/figures/3/auc_integral.pdf}
    \caption{Curva AUC del algoritmo Random Forest del dataset integral. La línea punteada corresponde a un predictor Random.}
    \label{fig:auc_integral}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.55]{documents/latex/figures/3/importances_integral.pdf}
    \caption{Los 10 atributos más importantes del dataset integral.}
    \label{fig:importances_integral}
\end{figure}

Ante esta situación una posible solución es usar algún método de ensamble que consiga potenciar al mejor de los dos modelos agregando las demás. Decidimos probar una serie de métodos clásicos de ensambling: Stacking, Bagging, y Boosting.

\todo{TO DO: Explicar métodos y exponer resultados.}
\todo{TO DO: Listar diferencias entre las variantes correctamente detectadas de los dos modelos.}
\todo{TO DO: Cambiar gráficos de AUC, cambiar train-test a uno solo. }

\todo{TO DO: Modificar diccionario de hiperparámetros del RF. Probar brevemente otros métodos para descartar que alguno sea muy superior.}

% \section{Uniendo las variables al Dataset VarQ}

% La siguiente pregunta es si el modelo mejora aún más sumando las variables de VarQ al conjunto de variables con los que trabajamos.


